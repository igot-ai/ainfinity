name: slm-finetune-gcp

resources:
  accelerators: L4:1  # L4 is good for Llama-3-8B, or T4:1 for cheaper
  cloud: gcp
  disk_size: 100  # GB

setup: |
  echo "Setting up environment..."
  pip install --upgrade pip
  pip install -r requirements.txt

  # Install Unsloth specific dependencies if needed (usually handled by pip install above if pointing to git)
  # pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

run: |
  echo "Starting training..."

  # Ensure WandB API key is available
  # You should set WANDB_API_KEY in your local environment or pass it via --env

  python train.py
